graph(%input1 : Float(1, 1, 224, 224),
      %inc.double_conv.0.weight : Float(64, 1, 3, 3),
      %inc.double_conv.0.bias : Float(64),
      %inc.double_conv.1.weight : Float(64),
      %inc.double_conv.1.bias : Float(64),
      %inc.double_conv.1.running_mean : Float(64),
      %inc.double_conv.1.running_var : Float(64),
      %inc.double_conv.1.num_batches_tracked : Long(),
      %inc.double_conv.3.weight : Float(64, 64, 3, 3),
      %inc.double_conv.3.bias : Float(64),
      %inc.double_conv.4.weight : Float(64),
      %inc.double_conv.4.bias : Float(64),
      %inc.double_conv.4.running_mean : Float(64),
      %inc.double_conv.4.running_var : Float(64),
      %inc.double_conv.4.num_batches_tracked : Long(),
      %down1.maxpool_conv.1.double_conv.0.weight : Float(128, 64, 3, 3),
      %down1.maxpool_conv.1.double_conv.0.bias : Float(128),
      %down1.maxpool_conv.1.double_conv.1.weight : Float(128),
      %down1.maxpool_conv.1.double_conv.1.bias : Float(128),
      %down1.maxpool_conv.1.double_conv.1.running_mean : Float(128),
      %down1.maxpool_conv.1.double_conv.1.running_var : Float(128),
      %down1.maxpool_conv.1.double_conv.1.num_batches_tracked : Long(),
      %down1.maxpool_conv.1.double_conv.3.weight : Float(128, 128, 3, 3),
      %down1.maxpool_conv.1.double_conv.3.bias : Float(128),
      %down1.maxpool_conv.1.double_conv.4.weight : Float(128),
      %down1.maxpool_conv.1.double_conv.4.bias : Float(128),
      %down1.maxpool_conv.1.double_conv.4.running_mean : Float(128),
      %down1.maxpool_conv.1.double_conv.4.running_var : Float(128),
      %down1.maxpool_conv.1.double_conv.4.num_batches_tracked : Long(),
      %down2.maxpool_conv.1.double_conv.0.weight : Float(256, 128, 3, 3),
      %down2.maxpool_conv.1.double_conv.0.bias : Float(256),
      %down2.maxpool_conv.1.double_conv.1.weight : Float(256),
      %down2.maxpool_conv.1.double_conv.1.bias : Float(256),
      %down2.maxpool_conv.1.double_conv.1.running_mean : Float(256),
      %down2.maxpool_conv.1.double_conv.1.running_var : Float(256),
      %down2.maxpool_conv.1.double_conv.1.num_batches_tracked : Long(),
      %down2.maxpool_conv.1.double_conv.3.weight : Float(256, 256, 3, 3),
      %down2.maxpool_conv.1.double_conv.3.bias : Float(256),
      %down2.maxpool_conv.1.double_conv.4.weight : Float(256),
      %down2.maxpool_conv.1.double_conv.4.bias : Float(256),
      %down2.maxpool_conv.1.double_conv.4.running_mean : Float(256),
      %down2.maxpool_conv.1.double_conv.4.running_var : Float(256),
      %down2.maxpool_conv.1.double_conv.4.num_batches_tracked : Long(),
      %down3.maxpool_conv.1.double_conv.0.weight : Float(512, 256, 3, 3),
      %down3.maxpool_conv.1.double_conv.0.bias : Float(512),
      %down3.maxpool_conv.1.double_conv.1.weight : Float(512),
      %down3.maxpool_conv.1.double_conv.1.bias : Float(512),
      %down3.maxpool_conv.1.double_conv.1.running_mean : Float(512),
      %down3.maxpool_conv.1.double_conv.1.running_var : Float(512),
      %down3.maxpool_conv.1.double_conv.1.num_batches_tracked : Long(),
      %down3.maxpool_conv.1.double_conv.3.weight : Float(512, 512, 3, 3),
      %down3.maxpool_conv.1.double_conv.3.bias : Float(512),
      %down3.maxpool_conv.1.double_conv.4.weight : Float(512),
      %down3.maxpool_conv.1.double_conv.4.bias : Float(512),
      %down3.maxpool_conv.1.double_conv.4.running_mean : Float(512),
      %down3.maxpool_conv.1.double_conv.4.running_var : Float(512),
      %down3.maxpool_conv.1.double_conv.4.num_batches_tracked : Long(),
      %down4.maxpool_conv.1.double_conv.0.weight : Float(512, 512, 3, 3),
      %down4.maxpool_conv.1.double_conv.0.bias : Float(512),
      %down4.maxpool_conv.1.double_conv.1.weight : Float(512),
      %down4.maxpool_conv.1.double_conv.1.bias : Float(512),
      %down4.maxpool_conv.1.double_conv.1.running_mean : Float(512),
      %down4.maxpool_conv.1.double_conv.1.running_var : Float(512),
      %down4.maxpool_conv.1.double_conv.1.num_batches_tracked : Long(),
      %down4.maxpool_conv.1.double_conv.3.weight : Float(512, 512, 3, 3),
      %down4.maxpool_conv.1.double_conv.3.bias : Float(512),
      %down4.maxpool_conv.1.double_conv.4.weight : Float(512),
      %down4.maxpool_conv.1.double_conv.4.bias : Float(512),
      %down4.maxpool_conv.1.double_conv.4.running_mean : Float(512),
      %down4.maxpool_conv.1.double_conv.4.running_var : Float(512),
      %down4.maxpool_conv.1.double_conv.4.num_batches_tracked : Long(),
      %up1.conv.double_conv.0.weight : Float(256, 1024, 3, 3),
      %up1.conv.double_conv.0.bias : Float(256),
      %up1.conv.double_conv.1.weight : Float(256),
      %up1.conv.double_conv.1.bias : Float(256),
      %up1.conv.double_conv.1.running_mean : Float(256),
      %up1.conv.double_conv.1.running_var : Float(256),
      %up1.conv.double_conv.1.num_batches_tracked : Long(),
      %up1.conv.double_conv.3.weight : Float(256, 256, 3, 3),
      %up1.conv.double_conv.3.bias : Float(256),
      %up1.conv.double_conv.4.weight : Float(256),
      %up1.conv.double_conv.4.bias : Float(256),
      %up1.conv.double_conv.4.running_mean : Float(256),
      %up1.conv.double_conv.4.running_var : Float(256),
      %up1.conv.double_conv.4.num_batches_tracked : Long(),
      %up2.conv.double_conv.0.weight : Float(128, 512, 3, 3),
      %up2.conv.double_conv.0.bias : Float(128),
      %up2.conv.double_conv.1.weight : Float(128),
      %up2.conv.double_conv.1.bias : Float(128),
      %up2.conv.double_conv.1.running_mean : Float(128),
      %up2.conv.double_conv.1.running_var : Float(128),
      %up2.conv.double_conv.1.num_batches_tracked : Long(),
      %up2.conv.double_conv.3.weight : Float(128, 128, 3, 3),
      %up2.conv.double_conv.3.bias : Float(128),
      %up2.conv.double_conv.4.weight : Float(128),
      %up2.conv.double_conv.4.bias : Float(128),
      %up2.conv.double_conv.4.running_mean : Float(128),
      %up2.conv.double_conv.4.running_var : Float(128),
      %up2.conv.double_conv.4.num_batches_tracked : Long(),
      %up3.conv.double_conv.0.weight : Float(64, 256, 3, 3),
      %up3.conv.double_conv.0.bias : Float(64),
      %up3.conv.double_conv.1.weight : Float(64),
      %up3.conv.double_conv.1.bias : Float(64),
      %up3.conv.double_conv.1.running_mean : Float(64),
      %up3.conv.double_conv.1.running_var : Float(64),
      %up3.conv.double_conv.1.num_batches_tracked : Long(),
      %up3.conv.double_conv.3.weight : Float(64, 64, 3, 3),
      %up3.conv.double_conv.3.bias : Float(64),
      %up3.conv.double_conv.4.weight : Float(64),
      %up3.conv.double_conv.4.bias : Float(64),
      %up3.conv.double_conv.4.running_mean : Float(64),
      %up3.conv.double_conv.4.running_var : Float(64),
      %up3.conv.double_conv.4.num_batches_tracked : Long(),
      %up4.conv.double_conv.0.weight : Float(64, 128, 3, 3),
      %up4.conv.double_conv.0.bias : Float(64),
      %up4.conv.double_conv.1.weight : Float(64),
      %up4.conv.double_conv.1.bias : Float(64),
      %up4.conv.double_conv.1.running_mean : Float(64),
      %up4.conv.double_conv.1.running_var : Float(64),
      %up4.conv.double_conv.1.num_batches_tracked : Long(),
      %up4.conv.double_conv.3.weight : Float(64, 64, 3, 3),
      %up4.conv.double_conv.3.bias : Float(64),
      %up4.conv.double_conv.4.weight : Float(64),
      %up4.conv.double_conv.4.bias : Float(64),
      %up4.conv.double_conv.4.running_mean : Float(64),
      %up4.conv.double_conv.4.running_var : Float(64),
      %up4.conv.double_conv.4.num_batches_tracked : Long(),
      %outc.conv.weight : Float(1, 64, 1, 1),
      %outc.conv.bias : Float(1)):
  %129 : Float(1, 64, 224, 224) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%input1, %inc.double_conv.0.weight, %inc.double_conv.0.bias), scope: UNet/DoubleConv[inc]/Sequential[double_conv]/Conv2d[0]
  %130 : Float(1, 64, 224, 224) = onnx::BatchNormalization[epsilon=1e-05, momentum=0.9](%129, %inc.double_conv.1.weight, %inc.double_conv.1.bias, %inc.double_conv.1.running_mean, %inc.double_conv.1.running_var), scope: UNet/DoubleConv[inc]/Sequential[double_conv]/BatchNorm2d[1]
  %131 : Float(1, 64, 224, 224) = onnx::Relu(%130), scope: UNet/DoubleConv[inc]/Sequential[double_conv]/ReLU[2]
  %132 : Float(1, 64, 224, 224) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%131, %inc.double_conv.3.weight, %inc.double_conv.3.bias), scope: UNet/DoubleConv[inc]/Sequential[double_conv]/Conv2d[3]
  %133 : Float(1, 64, 224, 224) = onnx::BatchNormalization[epsilon=1e-05, momentum=0.9](%132, %inc.double_conv.4.weight, %inc.double_conv.4.bias, %inc.double_conv.4.running_mean, %inc.double_conv.4.running_var), scope: UNet/DoubleConv[inc]/Sequential[double_conv]/BatchNorm2d[4]
  %134 : Float(1, 64, 224, 224) = onnx::Relu(%133), scope: UNet/DoubleConv[inc]/Sequential[double_conv]/ReLU[5]
  %135 : Float(1, 64, 112, 112) = onnx::MaxPool[kernel_shape=[2, 2], pads=[0, 0, 0, 0], strides=[2, 2]](%134), scope: UNet/Down[down1]/Sequential[maxpool_conv]/MaxPool2d[0]
  %136 : Float(1, 128, 112, 112) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%135, %down1.maxpool_conv.1.double_conv.0.weight, %down1.maxpool_conv.1.double_conv.0.bias), scope: UNet/Down[down1]/Sequential[maxpool_conv]/DoubleConv[1]/Sequential[double_conv]/Conv2d[0]
  %137 : Float(1, 128, 112, 112) = onnx::BatchNormalization[epsilon=1e-05, momentum=0.9](%136, %down1.maxpool_conv.1.double_conv.1.weight, %down1.maxpool_conv.1.double_conv.1.bias, %down1.maxpool_conv.1.double_conv.1.running_mean, %down1.maxpool_conv.1.double_conv.1.running_var), scope: UNet/Down[down1]/Sequential[maxpool_conv]/DoubleConv[1]/Sequential[double_conv]/BatchNorm2d[1]
  %138 : Float(1, 128, 112, 112) = onnx::Relu(%137), scope: UNet/Down[down1]/Sequential[maxpool_conv]/DoubleConv[1]/Sequential[double_conv]/ReLU[2]
  %139 : Float(1, 128, 112, 112) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%138, %down1.maxpool_conv.1.double_conv.3.weight, %down1.maxpool_conv.1.double_conv.3.bias), scope: UNet/Down[down1]/Sequential[maxpool_conv]/DoubleConv[1]/Sequential[double_conv]/Conv2d[3]
  %140 : Float(1, 128, 112, 112) = onnx::BatchNormalization[epsilon=1e-05, momentum=0.9](%139, %down1.maxpool_conv.1.double_conv.4.weight, %down1.maxpool_conv.1.double_conv.4.bias, %down1.maxpool_conv.1.double_conv.4.running_mean, %down1.maxpool_conv.1.double_conv.4.running_var), scope: UNet/Down[down1]/Sequential[maxpool_conv]/DoubleConv[1]/Sequential[double_conv]/BatchNorm2d[4]
  %141 : Float(1, 128, 112, 112) = onnx::Relu(%140), scope: UNet/Down[down1]/Sequential[maxpool_conv]/DoubleConv[1]/Sequential[double_conv]/ReLU[5]
  %142 : Float(1, 128, 56, 56) = onnx::MaxPool[kernel_shape=[2, 2], pads=[0, 0, 0, 0], strides=[2, 2]](%141), scope: UNet/Down[down2]/Sequential[maxpool_conv]/MaxPool2d[0]
  %143 : Float(1, 256, 56, 56) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%142, %down2.maxpool_conv.1.double_conv.0.weight, %down2.maxpool_conv.1.double_conv.0.bias), scope: UNet/Down[down2]/Sequential[maxpool_conv]/DoubleConv[1]/Sequential[double_conv]/Conv2d[0]
  %144 : Float(1, 256, 56, 56) = onnx::BatchNormalization[epsilon=1e-05, momentum=0.9](%143, %down2.maxpool_conv.1.double_conv.1.weight, %down2.maxpool_conv.1.double_conv.1.bias, %down2.maxpool_conv.1.double_conv.1.running_mean, %down2.maxpool_conv.1.double_conv.1.running_var), scope: UNet/Down[down2]/Sequential[maxpool_conv]/DoubleConv[1]/Sequential[double_conv]/BatchNorm2d[1]
  %145 : Float(1, 256, 56, 56) = onnx::Relu(%144), scope: UNet/Down[down2]/Sequential[maxpool_conv]/DoubleConv[1]/Sequential[double_conv]/ReLU[2]
  %146 : Float(1, 256, 56, 56) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%145, %down2.maxpool_conv.1.double_conv.3.weight, %down2.maxpool_conv.1.double_conv.3.bias), scope: UNet/Down[down2]/Sequential[maxpool_conv]/DoubleConv[1]/Sequential[double_conv]/Conv2d[3]
  %147 : Float(1, 256, 56, 56) = onnx::BatchNormalization[epsilon=1e-05, momentum=0.9](%146, %down2.maxpool_conv.1.double_conv.4.weight, %down2.maxpool_conv.1.double_conv.4.bias, %down2.maxpool_conv.1.double_conv.4.running_mean, %down2.maxpool_conv.1.double_conv.4.running_var), scope: UNet/Down[down2]/Sequential[maxpool_conv]/DoubleConv[1]/Sequential[double_conv]/BatchNorm2d[4]
  %148 : Float(1, 256, 56, 56) = onnx::Relu(%147), scope: UNet/Down[down2]/Sequential[maxpool_conv]/DoubleConv[1]/Sequential[double_conv]/ReLU[5]
  %149 : Float(1, 256, 28, 28) = onnx::MaxPool[kernel_shape=[2, 2], pads=[0, 0, 0, 0], strides=[2, 2]](%148), scope: UNet/Down[down3]/Sequential[maxpool_conv]/MaxPool2d[0]
  %150 : Float(1, 512, 28, 28) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%149, %down3.maxpool_conv.1.double_conv.0.weight, %down3.maxpool_conv.1.double_conv.0.bias), scope: UNet/Down[down3]/Sequential[maxpool_conv]/DoubleConv[1]/Sequential[double_conv]/Conv2d[0]
  %151 : Float(1, 512, 28, 28) = onnx::BatchNormalization[epsilon=1e-05, momentum=0.9](%150, %down3.maxpool_conv.1.double_conv.1.weight, %down3.maxpool_conv.1.double_conv.1.bias, %down3.maxpool_conv.1.double_conv.1.running_mean, %down3.maxpool_conv.1.double_conv.1.running_var), scope: UNet/Down[down3]/Sequential[maxpool_conv]/DoubleConv[1]/Sequential[double_conv]/BatchNorm2d[1]
  %152 : Float(1, 512, 28, 28) = onnx::Relu(%151), scope: UNet/Down[down3]/Sequential[maxpool_conv]/DoubleConv[1]/Sequential[double_conv]/ReLU[2]
  %153 : Float(1, 512, 28, 28) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%152, %down3.maxpool_conv.1.double_conv.3.weight, %down3.maxpool_conv.1.double_conv.3.bias), scope: UNet/Down[down3]/Sequential[maxpool_conv]/DoubleConv[1]/Sequential[double_conv]/Conv2d[3]
  %154 : Float(1, 512, 28, 28) = onnx::BatchNormalization[epsilon=1e-05, momentum=0.9](%153, %down3.maxpool_conv.1.double_conv.4.weight, %down3.maxpool_conv.1.double_conv.4.bias, %down3.maxpool_conv.1.double_conv.4.running_mean, %down3.maxpool_conv.1.double_conv.4.running_var), scope: UNet/Down[down3]/Sequential[maxpool_conv]/DoubleConv[1]/Sequential[double_conv]/BatchNorm2d[4]
  %155 : Float(1, 512, 28, 28) = onnx::Relu(%154), scope: UNet/Down[down3]/Sequential[maxpool_conv]/DoubleConv[1]/Sequential[double_conv]/ReLU[5]
  %156 : Float(1, 512, 14, 14) = onnx::MaxPool[kernel_shape=[2, 2], pads=[0, 0, 0, 0], strides=[2, 2]](%155), scope: UNet/Down[down4]/Sequential[maxpool_conv]/MaxPool2d[0]
  %157 : Float(1, 512, 14, 14) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%156, %down4.maxpool_conv.1.double_conv.0.weight, %down4.maxpool_conv.1.double_conv.0.bias), scope: UNet/Down[down4]/Sequential[maxpool_conv]/DoubleConv[1]/Sequential[double_conv]/Conv2d[0]
  %158 : Float(1, 512, 14, 14) = onnx::BatchNormalization[epsilon=1e-05, momentum=0.9](%157, %down4.maxpool_conv.1.double_conv.1.weight, %down4.maxpool_conv.1.double_conv.1.bias, %down4.maxpool_conv.1.double_conv.1.running_mean, %down4.maxpool_conv.1.double_conv.1.running_var), scope: UNet/Down[down4]/Sequential[maxpool_conv]/DoubleConv[1]/Sequential[double_conv]/BatchNorm2d[1]
  %159 : Float(1, 512, 14, 14) = onnx::Relu(%158), scope: UNet/Down[down4]/Sequential[maxpool_conv]/DoubleConv[1]/Sequential[double_conv]/ReLU[2]
  %160 : Float(1, 512, 14, 14) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%159, %down4.maxpool_conv.1.double_conv.3.weight, %down4.maxpool_conv.1.double_conv.3.bias), scope: UNet/Down[down4]/Sequential[maxpool_conv]/DoubleConv[1]/Sequential[double_conv]/Conv2d[3]
  %161 : Float(1, 512, 14, 14) = onnx::BatchNormalization[epsilon=1e-05, momentum=0.9](%160, %down4.maxpool_conv.1.double_conv.4.weight, %down4.maxpool_conv.1.double_conv.4.bias, %down4.maxpool_conv.1.double_conv.4.running_mean, %down4.maxpool_conv.1.double_conv.4.running_var), scope: UNet/Down[down4]/Sequential[maxpool_conv]/DoubleConv[1]/Sequential[double_conv]/BatchNorm2d[4]
  %162 : Float(1, 512, 14, 14) = onnx::Relu(%161), scope: UNet/Down[down4]/Sequential[maxpool_conv]/DoubleConv[1]/Sequential[double_conv]/ReLU[5]
  %163 : Tensor = onnx::Constant[value= 1  1  2  2 [ Variable[CPUType]{4} ]](), scope: UNet/Up[up1]
  %164 : Float(1, 512, 28, 28) = onnx::Upsample[mode="linear"](%162, %163), scope: UNet/Up[up1]
  %165 : Float(1, 1024, 28, 28) = onnx::Concat[axis=1](%155, %164), scope: UNet/Up[up1]
  %166 : Float(1, 256, 28, 28) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%165, %up1.conv.double_conv.0.weight, %up1.conv.double_conv.0.bias), scope: UNet/Up[up1]/DoubleConv[conv]/Sequential[double_conv]/Conv2d[0]
  %167 : Float(1, 256, 28, 28) = onnx::BatchNormalization[epsilon=1e-05, momentum=0.9](%166, %up1.conv.double_conv.1.weight, %up1.conv.double_conv.1.bias, %up1.conv.double_conv.1.running_mean, %up1.conv.double_conv.1.running_var), scope: UNet/Up[up1]/DoubleConv[conv]/Sequential[double_conv]/BatchNorm2d[1]
  %168 : Float(1, 256, 28, 28) = onnx::Relu(%167), scope: UNet/Up[up1]/DoubleConv[conv]/Sequential[double_conv]/ReLU[2]
  %169 : Float(1, 256, 28, 28) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%168, %up1.conv.double_conv.3.weight, %up1.conv.double_conv.3.bias), scope: UNet/Up[up1]/DoubleConv[conv]/Sequential[double_conv]/Conv2d[3]
  %170 : Float(1, 256, 28, 28) = onnx::BatchNormalization[epsilon=1e-05, momentum=0.9](%169, %up1.conv.double_conv.4.weight, %up1.conv.double_conv.4.bias, %up1.conv.double_conv.4.running_mean, %up1.conv.double_conv.4.running_var), scope: UNet/Up[up1]/DoubleConv[conv]/Sequential[double_conv]/BatchNorm2d[4]
  %171 : Float(1, 256, 28, 28) = onnx::Relu(%170), scope: UNet/Up[up1]/DoubleConv[conv]/Sequential[double_conv]/ReLU[5]
  %172 : Tensor = onnx::Constant[value= 1  1  2  2 [ Variable[CPUType]{4} ]](), scope: UNet/Up[up2]
  %173 : Float(1, 256, 56, 56) = onnx::Upsample[mode="linear"](%171, %172), scope: UNet/Up[up2]
  %174 : Float(1, 512, 56, 56) = onnx::Concat[axis=1](%148, %173), scope: UNet/Up[up2]
  %175 : Float(1, 128, 56, 56) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%174, %up2.conv.double_conv.0.weight, %up2.conv.double_conv.0.bias), scope: UNet/Up[up2]/DoubleConv[conv]/Sequential[double_conv]/Conv2d[0]
  %176 : Float(1, 128, 56, 56) = onnx::BatchNormalization[epsilon=1e-05, momentum=0.9](%175, %up2.conv.double_conv.1.weight, %up2.conv.double_conv.1.bias, %up2.conv.double_conv.1.running_mean, %up2.conv.double_conv.1.running_var), scope: UNet/Up[up2]/DoubleConv[conv]/Sequential[double_conv]/BatchNorm2d[1]
  %177 : Float(1, 128, 56, 56) = onnx::Relu(%176), scope: UNet/Up[up2]/DoubleConv[conv]/Sequential[double_conv]/ReLU[2]
  %178 : Float(1, 128, 56, 56) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%177, %up2.conv.double_conv.3.weight, %up2.conv.double_conv.3.bias), scope: UNet/Up[up2]/DoubleConv[conv]/Sequential[double_conv]/Conv2d[3]
  %179 : Float(1, 128, 56, 56) = onnx::BatchNormalization[epsilon=1e-05, momentum=0.9](%178, %up2.conv.double_conv.4.weight, %up2.conv.double_conv.4.bias, %up2.conv.double_conv.4.running_mean, %up2.conv.double_conv.4.running_var), scope: UNet/Up[up2]/DoubleConv[conv]/Sequential[double_conv]/BatchNorm2d[4]
  %180 : Float(1, 128, 56, 56) = onnx::Relu(%179), scope: UNet/Up[up2]/DoubleConv[conv]/Sequential[double_conv]/ReLU[5]
  %181 : Tensor = onnx::Constant[value= 1  1  2  2 [ Variable[CPUType]{4} ]](), scope: UNet/Up[up3]
  %182 : Float(1, 128, 112, 112) = onnx::Upsample[mode="linear"](%180, %181), scope: UNet/Up[up3]
  %183 : Float(1, 256, 112, 112) = onnx::Concat[axis=1](%141, %182), scope: UNet/Up[up3]
  %184 : Float(1, 64, 112, 112) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%183, %up3.conv.double_conv.0.weight, %up3.conv.double_conv.0.bias), scope: UNet/Up[up3]/DoubleConv[conv]/Sequential[double_conv]/Conv2d[0]
  %185 : Float(1, 64, 112, 112) = onnx::BatchNormalization[epsilon=1e-05, momentum=0.9](%184, %up3.conv.double_conv.1.weight, %up3.conv.double_conv.1.bias, %up3.conv.double_conv.1.running_mean, %up3.conv.double_conv.1.running_var), scope: UNet/Up[up3]/DoubleConv[conv]/Sequential[double_conv]/BatchNorm2d[1]
  %186 : Float(1, 64, 112, 112) = onnx::Relu(%185), scope: UNet/Up[up3]/DoubleConv[conv]/Sequential[double_conv]/ReLU[2]
  %187 : Float(1, 64, 112, 112) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%186, %up3.conv.double_conv.3.weight, %up3.conv.double_conv.3.bias), scope: UNet/Up[up3]/DoubleConv[conv]/Sequential[double_conv]/Conv2d[3]
  %188 : Float(1, 64, 112, 112) = onnx::BatchNormalization[epsilon=1e-05, momentum=0.9](%187, %up3.conv.double_conv.4.weight, %up3.conv.double_conv.4.bias, %up3.conv.double_conv.4.running_mean, %up3.conv.double_conv.4.running_var), scope: UNet/Up[up3]/DoubleConv[conv]/Sequential[double_conv]/BatchNorm2d[4]
  %189 : Float(1, 64, 112, 112) = onnx::Relu(%188), scope: UNet/Up[up3]/DoubleConv[conv]/Sequential[double_conv]/ReLU[5]
  %190 : Tensor = onnx::Constant[value= 1  1  2  2 [ Variable[CPUType]{4} ]](), scope: UNet/Up[up4]
  %191 : Float(1, 64, 224, 224) = onnx::Upsample[mode="linear"](%189, %190), scope: UNet/Up[up4]
  %192 : Float(1, 128, 224, 224) = onnx::Concat[axis=1](%134, %191), scope: UNet/Up[up4]
  %193 : Float(1, 64, 224, 224) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%192, %up4.conv.double_conv.0.weight, %up4.conv.double_conv.0.bias), scope: UNet/Up[up4]/DoubleConv[conv]/Sequential[double_conv]/Conv2d[0]
  %194 : Float(1, 64, 224, 224) = onnx::BatchNormalization[epsilon=1e-05, momentum=0.9](%193, %up4.conv.double_conv.1.weight, %up4.conv.double_conv.1.bias, %up4.conv.double_conv.1.running_mean, %up4.conv.double_conv.1.running_var), scope: UNet/Up[up4]/DoubleConv[conv]/Sequential[double_conv]/BatchNorm2d[1]
  %195 : Float(1, 64, 224, 224) = onnx::Relu(%194), scope: UNet/Up[up4]/DoubleConv[conv]/Sequential[double_conv]/ReLU[2]
  %196 : Float(1, 64, 224, 224) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%195, %up4.conv.double_conv.3.weight, %up4.conv.double_conv.3.bias), scope: UNet/Up[up4]/DoubleConv[conv]/Sequential[double_conv]/Conv2d[3]
  %197 : Float(1, 64, 224, 224) = onnx::BatchNormalization[epsilon=1e-05, momentum=0.9](%196, %up4.conv.double_conv.4.weight, %up4.conv.double_conv.4.bias, %up4.conv.double_conv.4.running_mean, %up4.conv.double_conv.4.running_var), scope: UNet/Up[up4]/DoubleConv[conv]/Sequential[double_conv]/BatchNorm2d[4]
  %198 : Float(1, 64, 224, 224) = onnx::Relu(%197), scope: UNet/Up[up4]/DoubleConv[conv]/Sequential[double_conv]/ReLU[5]
  %output1 : Float(1, 1, 224, 224) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%198, %outc.conv.weight, %outc.conv.bias), scope: UNet/OutConv[outc]/Conv2d[conv]
  return (%output1)

